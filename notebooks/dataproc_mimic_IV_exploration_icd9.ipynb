{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import datasets\n",
    "import log_reg\n",
    "from dataproc import extract_wvs\n",
    "from dataproc import get_discharge_summaries\n",
    "from dataproc import concat_and_split\n",
    "from dataproc import build_vocab\n",
    "from dataproc import vocab_index_descriptions\n",
    "from dataproc import word_embeddings\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC_4_DIR='/Users/kathyx/Documents/研二下课程/6120/final_project/data/mimic4/mimic-iv-3.1'\n",
    "MIMIC_4_DIR='../../data/mimic4/mimic-iv-3.1'\n",
    "MIMIC_4_SAVE_DIR='../mimicdata/mimic4_icd9'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data processing in a much better way, with a notebook.\n",
    "\n",
    "First, let's define some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = 'full' #use all available labels in the dataset for prediction\n",
    "notes_file = f'{MIMIC_4_DIR}/note/discharge.csv' # raw note events downloaded from MIMIC-III\n",
    "vocab_size = 'full' #don't limit the vocab size to a specific number\n",
    "vocab_min = 3 #discard tokens appearing in fewer than this many documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine diagnosis and procedure codes and reformat them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes in MIMIC-IV are given in separate files for procedures and diagnoses, and the codes are given without periods, which might lead to collisions if we naively combine them. So we have to add the periods back in the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfproc = pd.read_csv(f'{MIMIC_4_DIR}/hosp/procedures_icd.csv',\n",
    "                     dtype={\"icd_code\": str})\n",
    "dfdiag = pd.read_csv(f'{MIMIC_4_DIR}/hosp/diagnoses_icd.csv',\n",
    "                     dtype={\"icd_code\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469209\n",
      "390446\n",
      "859655\n"
     ]
    }
   ],
   "source": [
    "print(len(dfproc[dfproc['icd_version']==9]))\n",
    "print(len(dfproc[dfproc['icd_version']==10]))\n",
    "print(len(dfproc['icd_version']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC IV contains both ICD-9 and ICD-10 code versions; however, for the purposes of processing ICD9-9 codes, we will restrict our focus to ICD-9 codes only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproc9=dfproc[dfproc['icd_version']==9]\n",
    "dfdiag9=dfdiag[dfdiag['icd_version']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-05-07</td>\n",
       "      <td>5491</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-06-27</td>\n",
       "      <td>5491</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-08-06</td>\n",
       "      <td>5491</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000068</td>\n",
       "      <td>25022803</td>\n",
       "      <td>1</td>\n",
       "      <td>2160-03-03</td>\n",
       "      <td>8938</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000280</td>\n",
       "      <td>25852320</td>\n",
       "      <td>1</td>\n",
       "      <td>2151-03-18</td>\n",
       "      <td>8938</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num   chartdate icd_code  icd_version\n",
       "0    10000032  22595853        1  2180-05-07     5491            9\n",
       "1    10000032  22841357        1  2180-06-27     5491            9\n",
       "2    10000032  25742920        1  2180-08-06     5491            9\n",
       "3    10000068  25022803        1  2160-03-03     8938            9\n",
       "5    10000280  25852320        1  2151-03-18     8938            9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "dfproc9.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>5723</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>78959</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>3</td>\n",
       "      <td>5715</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>4</td>\n",
       "      <td>07070</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>5</td>\n",
       "      <td>496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num icd_code  icd_version\n",
       "0    10000032  22595853        1     5723            9\n",
       "1    10000032  22595853        2    78959            9\n",
       "2    10000032  22595853        3     5715            9\n",
       "3    10000032  22595853        4    07070            9\n",
       "4    10000032  22595853        5      496            9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "dfdiag9.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/wg8tvf2x5pg4jwptyghyn9280000gn/T/ipykernel_87452/3462705871.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dfdiag9['absolute_code'] = dfdiag9.apply(lambda row: str(datasets.reformat(str(row[3]), True)), axis=1)\n",
      "/var/folders/4d/wg8tvf2x5pg4jwptyghyn9280000gn/T/ipykernel_87452/3462705871.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfdiag9['absolute_code'] = dfdiag9.apply(lambda row: str(datasets.reformat(str(row[3]), True)), axis=1)\n",
      "/var/folders/4d/wg8tvf2x5pg4jwptyghyn9280000gn/T/ipykernel_87452/3462705871.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dfproc9['absolute_code'] = dfproc9.apply(lambda row: str(datasets.reformat(str(row[4]), False)), axis=1)\n",
      "/var/folders/4d/wg8tvf2x5pg4jwptyghyn9280000gn/T/ipykernel_87452/3462705871.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfproc9['absolute_code'] = dfproc9.apply(lambda row: str(datasets.reformat(str(row[4]), False)), axis=1)\n"
     ]
    }
   ],
   "source": [
    "dfdiag9['absolute_code'] = dfdiag9.apply(lambda row: str(datasets.reformat(str(row[3]), True)), axis=1)\n",
    "dfproc9['absolute_code'] = dfproc9.apply(lambda row: str(datasets.reformat(str(row[4]), False)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>absolute_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>5723</td>\n",
       "      <td>9</td>\n",
       "      <td>572.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>78959</td>\n",
       "      <td>9</td>\n",
       "      <td>789.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>3</td>\n",
       "      <td>5715</td>\n",
       "      <td>9</td>\n",
       "      <td>571.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>4</td>\n",
       "      <td>07070</td>\n",
       "      <td>9</td>\n",
       "      <td>070.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>5</td>\n",
       "      <td>496</td>\n",
       "      <td>9</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num icd_code  icd_version absolute_code\n",
       "0    10000032  22595853        1     5723            9         572.3\n",
       "1    10000032  22595853        2    78959            9        789.59\n",
       "2    10000032  22595853        3     5715            9         571.5\n",
       "3    10000032  22595853        4    07070            9        070.70\n",
       "4    10000032  22595853        5      496            9           496"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "dfdiag9.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>absolute_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-05-07</td>\n",
       "      <td>5491</td>\n",
       "      <td>9</td>\n",
       "      <td>54.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-06-27</td>\n",
       "      <td>5491</td>\n",
       "      <td>9</td>\n",
       "      <td>54.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>1</td>\n",
       "      <td>2180-08-06</td>\n",
       "      <td>5491</td>\n",
       "      <td>9</td>\n",
       "      <td>54.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000068</td>\n",
       "      <td>25022803</td>\n",
       "      <td>1</td>\n",
       "      <td>2160-03-03</td>\n",
       "      <td>8938</td>\n",
       "      <td>9</td>\n",
       "      <td>89.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000280</td>\n",
       "      <td>25852320</td>\n",
       "      <td>1</td>\n",
       "      <td>2151-03-18</td>\n",
       "      <td>8938</td>\n",
       "      <td>9</td>\n",
       "      <td>89.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num   chartdate icd_code  icd_version  \\\n",
       "0    10000032  22595853        1  2180-05-07     5491            9   \n",
       "1    10000032  22841357        1  2180-06-27     5491            9   \n",
       "2    10000032  25742920        1  2180-08-06     5491            9   \n",
       "3    10000068  25022803        1  2160-03-03     8938            9   \n",
       "5    10000280  25852320        1  2151-03-18     8938            9   \n",
       "\n",
       "  absolute_code  \n",
       "0         54.91  \n",
       "1         54.91  \n",
       "2         54.91  \n",
       "3         89.38  \n",
       "5         89.38  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "dfproc9.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcodes9 = pd.concat([dfdiag9, dfproc9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>absolute_code</th>\n",
       "      <th>chartdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>5723</td>\n",
       "      <td>9</td>\n",
       "      <td>572.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>78959</td>\n",
       "      <td>9</td>\n",
       "      <td>789.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>3</td>\n",
       "      <td>5715</td>\n",
       "      <td>9</td>\n",
       "      <td>571.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>4</td>\n",
       "      <td>07070</td>\n",
       "      <td>9</td>\n",
       "      <td>070.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>5</td>\n",
       "      <td>496</td>\n",
       "      <td>9</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num icd_code  icd_version absolute_code chartdate\n",
       "0    10000032  22595853        1     5723            9         572.3       NaN\n",
       "1    10000032  22595853        2    78959            9        789.59       NaN\n",
       "2    10000032  22595853        3     5715            9         571.5       NaN\n",
       "3    10000032  22595853        4    07070            9        070.70       NaN\n",
       "4    10000032  22595853        5      496            9           496       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "dfcodes9.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcodes9.to_csv(f'{MIMIC_4_SAVE_DIR}/ALL_CODES.csv', index=False,\n",
    "               columns=['subject_id', 'hadm_id', 'seq_num', 'absolute_code'],\n",
    "               header=['subject_id', 'hadm_id', 'seq_num', 'ICD9_CODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many codes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11700"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In the full dataset (not just discharge summaries)\n",
    "df = pd.read_csv('%s/ALL_CODES.csv' % MIMIC_4_SAVE_DIR, dtype={\"ICD9_CODE\": str})\n",
    "len(df['ICD9_CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>572.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>789.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>3</td>\n",
       "      <td>571.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>4</td>\n",
       "      <td>070.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>5</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num ICD9_CODE\n",
       "0    10000032  22595853        1     572.3\n",
       "1    10000032  22595853        2    789.59\n",
       "2    10000032  22595853        3     571.5\n",
       "3    10000032  22595853        4    070.70\n",
       "4    10000032  22595853        5       496"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "df.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and preprocess raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing time!\n",
    "\n",
    "This will:\n",
    "- Select only discharge summaries and their addenda\n",
    "- remove punctuation and numeric-only tokens, removing 500 but keeping 250mg\n",
    "- lowercase all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Reads NOTEEVENTS file, finds the discharge summaries, preprocesses them and writes out the filtered dataset.\n",
    "\"\"\"\n",
    "import csv\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#retain only alphanumeric\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def write_discharge_summaries(out_file, data_dir):\n",
    "    # notes_file = '%s/NOTEEVENTS.csv' % (data_dir)\n",
    "    notes_file = f'{data_dir}/note/discharge.csv'\n",
    "    print(\"processing notes file\")\n",
    "    with open(notes_file, 'r', encoding='utf-8') as csvfile:\n",
    "        with open(out_file, 'w', encoding='utf-8') as outfile:\n",
    "            print(\"writing to %s\" % (out_file))\n",
    "            outfile.write(','.join(['subject_id', 'hadm_id', 'charttime', 'text']) + '\\n')\n",
    "            notereader = csv.reader(csvfile)\n",
    "            #header\n",
    "            next(notereader)\n",
    "            i = 0\n",
    "            for line in tqdm(notereader):\n",
    "                subj = int(line[1])\n",
    "                category = line[3]\n",
    "                if category == \"DS\":\n",
    "                    note = line[7]\n",
    "                    #tokenize, lowercase and remove numerics\n",
    "                    tokens = [t.lower() for t in tokenizer.tokenize(note) if not t.isnumeric()]\n",
    "                    text = '\"' + ' '.join(tokens) + '\"'\n",
    "                    outfile.write(','.join([line[1], line[2], line[5], text]) + '\\n')\n",
    "                i += 1\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing notes file\n",
      "writing to ../mimicdata/mimic4_icd9/disch_9_full.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331793it [02:19, 2377.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#This reads all notes, selects only the discharge summaries, and tokenizes them, returning the output filename\n",
    "disch_full_file = write_discharge_summaries(out_file=f\"{MIMIC_4_SAVE_DIR}/disch_9_full.csv\",data_dir= MIMIC_4_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read this in and see what kind of data we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{MIMIC_4_SAVE_DIR}/disch_9_full.csv\", dtype={'subject_id': str, 'hadm_id': str}, encoding='utf-8', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-07 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-27 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-25 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-07 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>2160-11-25 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id   hadm_id            charttime  \\\n",
       "0   10000032  22595853  2180-05-07 00:00:00   \n",
       "1   10000032  22841357  2180-06-27 00:00:00   \n",
       "2   10000032  29079034  2180-07-25 00:00:00   \n",
       "3   10000032  25742920  2180-08-07 00:00:00   \n",
       "4   10000084  23052089  2160-11-25 00:00:00   \n",
       "\n",
       "                                                text  \n",
       "0  name ___ unit no ___ admission date ___ discha...  \n",
       "1  name ___ unit no ___ admission date ___ discha...  \n",
       "2  name ___ unit no ___ admission date ___ discha...  \n",
       "3  name ___ unit no ___ admission date ___ discha...  \n",
       "4  name ___ unit no ___ admission date ___ discha...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "df.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331793"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many admissions?\n",
    "len(df['hadm_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145914\n",
      "331793\n"
     ]
    }
   ],
   "source": [
    "print(len(df['subject_id'].unique()))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokens and types\n",
    "types = set()\n",
    "num_tok = 0\n",
    "for row in df.itertuples():\n",
    "    for w in row[4].split():\n",
    "        types.add(w)\n",
    "        num_tok += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num types 370511\n",
      "Num tokens 508950426\n"
     ]
    }
   ],
   "source": [
    "print(\"Num types\", len(types))\n",
    "print(\"Num tokens\", str(num_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's sort by SUBJECT_ID and HADM_ID to make a correspondence with the MIMIC-3 label file\n",
    "df = df.sort_values(['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the label file by the same\n",
    "dfl = pd.read_csv(f'{MIMIC_4_SAVE_DIR}/ALL_CODES.csv',dtype={\"ICD9_CODE\": str})\n",
    "dfl = dfl.sort_values(['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331793, 291156)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['hadm_id'].unique()), len(dfl['hadm_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate labels with set of discharge summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there were some HADM_ID's that didn't have discharge summaries, so they weren't included with our notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's filter out these HADM_ID's\n",
    "hadm_ids = set(df['hadm_id'])\n",
    "with open(f'{MIMIC_4_SAVE_DIR}/ALL_CODES.csv', 'r') as lf:\n",
    "    with open(f'{MIMIC_4_SAVE_DIR}/ALL_CODES_filtered.csv','w') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['subject_id', 'hadm_id', 'icd9_code', 'admittime', 'dischtime'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            hadm_id = row[1]\n",
    "            #print(hadm_id)\n",
    "            #break\n",
    "            if hadm_id in hadm_ids:\n",
    "                w.writerow(row[:2] + [row[-1], '', ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some HADM_ID's that didn't have labels, so they weren't included with our notes.\n",
    "We need to remove the note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = pd.read_csv(f'{MIMIC_4_SAVE_DIR}/ALL_CODES_filtered.csv',dtype={\"icd9_code\": str}, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2815287"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209330"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfl['hadm_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's filter out these HADM_ID in the note but not in the label\n",
    "hadm_lids = set(dfl['hadm_id'])\n",
    "with open(f'{MIMIC_4_SAVE_DIR}/disch_9_full.csv', 'r', encoding='utf-8') as lf:\n",
    "    with open(f'{MIMIC_4_SAVE_DIR}/disch_9_filtered.csv','w', encoding='utf-8') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['subject_id', 'hadm_id', 'charttime', 'text'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            hadm_id = int(row[1])\n",
    "            # hadm_id = row[1]\n",
    "            #print(hadm_id)\n",
    "            #break\n",
    "            if hadm_id in hadm_lids:\n",
    "                w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd9_code</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>572.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>789.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>571.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>070.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id icd9_code  admittime  dischtime\n",
       "0    10000032  22595853     572.3        NaN        NaN\n",
       "1    10000032  22595853    789.59        NaN        NaN\n",
       "2    10000032  22595853     571.5        NaN        NaN\n",
       "3    10000032  22595853    070.70        NaN        NaN\n",
       "4    10000032  22595853       496        NaN        NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "dfl.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we still need to sort it by HADM_ID\n",
    "dfl = dfl.sort_values(['subject_id', 'hadm_id'])\n",
    "dfl.to_csv(f'{MIMIC_4_SAVE_DIR}/ALL_CODES_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append labels to notes in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's append each instance with all of its codes\n",
    "#this is pretty non-trivial so let's use this script I wrote, which requires the notes to be written to file\n",
    "df = pd.read_csv(f'{MIMIC_4_SAVE_DIR}/disch_9_filtered.csv', index_col=None, encoding='utf-8', engine='python')\n",
    "df = df.sort_values(['subject_id', 'hadm_id'])\n",
    "sorted_file = f'{MIMIC_4_SAVE_DIR}/disch_9_filtered.csv'\n",
    "df.to_csv(sorted_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209330\n",
      "209330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df['hadm_id'].unique()))\n",
    "print(len(dfl['hadm_id'].unique()))\n",
    "set(dfl['hadm_id'].unique()).issubset(set(df['hadm_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['hadm_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97708\n",
      "97708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df['subject_id'].unique()))\n",
    "print(len(dfl['subject_id'].unique()))\n",
    "set(int(x) for x in dfl['subject_id'].unique()).issubset(set(df['subject_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Concatenate the labels with the notes data and split using the saved splits\n",
    "\"\"\"\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "def concat_data(labelsfile, notes_file):\n",
    "    \"\"\"\n",
    "        INPUTS:\n",
    "            labelsfile: sorted by hadm id, contains one label per line\n",
    "            notes_file: sorted by hadm id, contains one note per line\n",
    "    \"\"\"\n",
    "    with open(labelsfile, 'r', encoding='utf-8') as lf:\n",
    "        print(\"CONCATENATING\")\n",
    "        with open(notes_file, 'r', encoding='utf-8') as notesfile:\n",
    "            outfilename = f'{MIMIC_4_SAVE_DIR}/notes_labeled_icd9_filtered.csv'\n",
    "            with open(outfilename, 'w', encoding='utf-8') as outfile:\n",
    "                w = csv.writer(outfile)\n",
    "                w.writerow(['subject_id', 'hadm_id', 'text', 'labels'])\n",
    "\n",
    "                labels_gen = next_labels(lf)\n",
    "                notes_gen = next_notes(notesfile)\n",
    "\n",
    "                for i, (subj_id, text, hadm_id) in enumerate(notes_gen):\n",
    "                    if i % 10000 == 0:\n",
    "                        print(str(i) + \" done\")\n",
    "                    cur_subj, cur_labels, cur_hadm = next(labels_gen)\n",
    "\n",
    "                    if cur_hadm == hadm_id:\n",
    "                        w.writerow([subj_id, str(hadm_id), text, ';'.join(cur_labels)])\n",
    "                    else:\n",
    "                        print(\"couldn't find matching hadm_id. data is probably not sorted correctly\")\n",
    "                        break\n",
    "                    \n",
    "    return outfilename\n",
    "\n",
    "def next_labels(labelsfile):\n",
    "    \"\"\"\n",
    "        Generator for label sets from the label file\n",
    "    \"\"\"\n",
    "    labels_reader = csv.reader(labelsfile)\n",
    "    #header\n",
    "    next(labels_reader)\n",
    "\n",
    "    first_label_line = next(labels_reader)\n",
    "\n",
    "    cur_subj = int(first_label_line[0])\n",
    "    cur_hadm = int(first_label_line[1])\n",
    "    cur_labels = [first_label_line[2]]\n",
    "\n",
    "    for row in labels_reader:\n",
    "        subj_id = int(row[0])\n",
    "        hadm_id = int(row[1])\n",
    "        code = row[2]\n",
    "        #keep reading until you hit a new hadm id\n",
    "        if hadm_id != cur_hadm or subj_id != cur_subj:\n",
    "            yield cur_subj, cur_labels, cur_hadm\n",
    "            cur_labels = [code]\n",
    "            cur_subj = subj_id\n",
    "            cur_hadm = hadm_id\n",
    "        else:\n",
    "            #add to the labels and move on\n",
    "            cur_labels.append(code)\n",
    "    yield cur_subj, cur_labels, cur_hadm\n",
    "\n",
    "def next_notes(notesfile):\n",
    "    \"\"\"\n",
    "        Generator for notes from the notes file\n",
    "        This will also concatenate discharge summaries and their addenda, which have the same subject and hadm id\n",
    "    \"\"\"\n",
    "    nr = csv.reader(notesfile)\n",
    "    #header\n",
    "    next(nr)\n",
    "\n",
    "    first_note = next(nr)\n",
    "\n",
    "    cur_subj = int(first_note[0])\n",
    "    cur_hadm = int(first_note[1])\n",
    "    cur_text = first_note[3]\n",
    "    \n",
    "    for row in nr:\n",
    "        subj_id = int(row[0])\n",
    "        hadm_id = int(row[1])\n",
    "        text = row[3]\n",
    "        #keep reading until you hit a new hadm id\n",
    "        if hadm_id != cur_hadm or subj_id != cur_subj:\n",
    "            yield cur_subj, cur_text, cur_hadm\n",
    "            cur_text = text\n",
    "            cur_subj = subj_id\n",
    "            cur_hadm = hadm_id\n",
    "        else:\n",
    "            #concatenate to the discharge summary and move on\n",
    "            cur_text += \" \" + text\n",
    "    yield cur_subj, cur_text, cur_hadm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-07 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-27 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-07 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-25 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000248</td>\n",
       "      <td>20600184</td>\n",
       "      <td>2192-11-30 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000560</td>\n",
       "      <td>28979390</td>\n",
       "      <td>2189-10-17 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000764</td>\n",
       "      <td>27897940</td>\n",
       "      <td>2132-10-19 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000826</td>\n",
       "      <td>20032235</td>\n",
       "      <td>2146-12-12 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000826</td>\n",
       "      <td>21086876</td>\n",
       "      <td>2146-12-24 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000826</td>\n",
       "      <td>28289260</td>\n",
       "      <td>2147-01-02 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id            charttime  \\\n",
       "0    10000032  22595853  2180-05-07 00:00:00   \n",
       "1    10000032  22841357  2180-06-27 00:00:00   \n",
       "3    10000032  25742920  2180-08-07 00:00:00   \n",
       "2    10000032  29079034  2180-07-25 00:00:00   \n",
       "4    10000248  20600184  2192-11-30 00:00:00   \n",
       "5    10000560  28979390  2189-10-17 00:00:00   \n",
       "6    10000764  27897940  2132-10-19 00:00:00   \n",
       "7    10000826  20032235  2146-12-12 00:00:00   \n",
       "8    10000826  21086876  2146-12-24 00:00:00   \n",
       "9    10000826  28289260  2147-01-02 00:00:00   \n",
       "\n",
       "                                                text  \n",
       "0  name ___ unit no ___ admission date ___ discha...  \n",
       "1  name ___ unit no ___ admission date ___ discha...  \n",
       "3  name ___ unit no ___ admission date ___ discha...  \n",
       "2  name ___ unit no ___ admission date ___ discha...  \n",
       "4  name ___ unit no ___ admission date ___ discha...  \n",
       "5  name ___ unit no ___ admission date ___ discha...  \n",
       "6  name ___ unit no ___ admission date ___ discha...  \n",
       "7  name ___ unit no ___ admission date ___ discha...  \n",
       "8  name ___ unit no ___ admission date ___ discha...  \n",
       "9  name ___ unit no ___ admission date ___ discha...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd9_code</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>572.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>789.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>571.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>070.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>296.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>309.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>V15.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441408</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>54.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>070.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id   hadm_id icd9_code  admittime  dischtime\n",
       "0          10000032  22595853     572.3        NaN        NaN\n",
       "1          10000032  22595853    789.59        NaN        NaN\n",
       "2          10000032  22595853     571.5        NaN        NaN\n",
       "3          10000032  22595853    070.70        NaN        NaN\n",
       "4          10000032  22595853       496        NaN        NaN\n",
       "5          10000032  22595853    296.80        NaN        NaN\n",
       "6          10000032  22595853    309.81        NaN        NaN\n",
       "7          10000032  22595853    V15.82        NaN        NaN\n",
       "2441408    10000032  22595853     54.91        NaN        NaN\n",
       "8          10000032  22841357    070.71        NaN        NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONCATENATING\n",
      "0 done\n",
      "10000 done\n",
      "20000 done\n",
      "30000 done\n",
      "40000 done\n",
      "50000 done\n",
      "60000 done\n",
      "70000 done\n",
      "80000 done\n",
      "90000 done\n",
      "100000 done\n",
      "110000 done\n",
      "120000 done\n",
      "130000 done\n",
      "140000 done\n",
      "150000 done\n",
      "160000 done\n",
      "170000 done\n",
      "180000 done\n",
      "190000 done\n",
      "200000 done\n"
     ]
    }
   ],
   "source": [
    "#For this cell, I do not recommend to run this cell directly.\n",
    "#You can run through the file data_mimic_IV_concate_note_label.py\n",
    "#Remember to change the directories there: MIMIC_4_SAVE_DIR, labelsfile,notes_file, output_note_labeled_file\n",
    "labeled = concat_data(f'{MIMIC_4_SAVE_DIR}/ALL_CODES_filtered.csv', f'{MIMIC_4_SAVE_DIR}/disch_9_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check the combined data we just made. Do we have all hadm id's accounted for, and the same vocab stats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfnl = pd.read_csv(f'{MIMIC_4_SAVE_DIR}/notes_labeled_icd9_filtered.csv', encoding='utf-8', engine='python')\n",
    "#Tokens and types\n",
    "types = set()\n",
    "num_tok = 0\n",
    "for row in dfnl.itertuples():\n",
    "    for w in row[3].split():\n",
    "        types.add(w)\n",
    "        num_tok += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num types 298427 num tokens 305530808\n"
     ]
    }
   ],
   "source": [
    "print(\"num types\", len(types), \"num tokens\", num_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209330"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnl['hadm_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209330"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97708"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnl['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(labeledfile, base_name):\n",
    "    print(\"SPLITTING\")\n",
    "    #create and write headers for train, dev, test\n",
    "    train_name = '%s_train_split.csv' % (base_name)\n",
    "    dev_name = '%s_dev_split.csv' % (base_name)\n",
    "    test_name = '%s_test_split.csv' % (base_name)\n",
    "    train_file = open(train_name, 'w', encoding='utf-8')\n",
    "    dev_file = open(dev_name, 'w', encoding='utf-8')\n",
    "    test_file = open(test_name, 'w', encoding='utf-8')\n",
    "    train_file.write(','.join(['subject_id', 'hadm_id', 'text', 'labels']) + \"\\n\")\n",
    "    dev_file.write(','.join(['subject_id', 'hadm_id', 'text', 'labels']) + \"\\n\")\n",
    "    test_file.write(','.join(['subject_id', 'hadm_id', 'text', 'labels']) + \"\\n\")\n",
    "\n",
    "    hadm_ids = {}\n",
    "\n",
    "    #read in train, dev, test splits\n",
    "    for splt in ['train', 'dev', 'test']:\n",
    "        hadm_ids[splt] = set()\n",
    "        with open('%s/%s_full_hadm_ids.csv' % (MIMIC_4_SAVE_DIR, splt), 'r') as f:\n",
    "            for line in f:\n",
    "                hadm_ids[splt].add(line.rstrip())\n",
    "\n",
    "    with open(labeledfile, 'r', encoding='utf-8') as lf:\n",
    "        reader = csv.reader(lf)\n",
    "        next(reader)\n",
    "        i = 0\n",
    "        cur_hadm = 0\n",
    "        for row in reader:\n",
    "            #filter text, write to file according to train/dev/test split\n",
    "            if i % 10000 == 0:\n",
    "                print(str(i) + \" read\")\n",
    "\n",
    "            hadm_id = row[1]\n",
    "\n",
    "            if hadm_id in hadm_ids['train']:\n",
    "                train_file.write(','.join(row) + \"\\n\")\n",
    "            elif hadm_id in hadm_ids['dev']:\n",
    "                dev_file.write(','.join(row) + \"\\n\")\n",
    "            elif hadm_id in hadm_ids['test']:\n",
    "                test_file.write(','.join(row) + \"\\n\")\n",
    "            else:\n",
    "                print(\"Error\")\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        train_file.close()\n",
    "        dev_file.close()\n",
    "        test_file.close()\n",
    "    return train_name, dev_name, test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING\n",
      "0 read\n",
      "Error\n",
      "10000 read\n",
      "Error\n",
      "20000 read\n",
      "30000 read\n",
      "40000 read\n",
      "50000 read\n",
      "60000 read\n",
      "70000 read\n",
      "Error\n",
      "80000 read\n",
      "Error\n",
      "90000 read\n",
      "100000 read\n",
      "Error\n",
      "110000 read\n",
      "120000 read\n",
      "130000 read\n",
      "140000 read\n",
      "Error\n",
      "150000 read\n",
      "160000 read\n",
      "170000 read\n",
      "180000 read\n",
      "Error\n",
      "190000 read\n",
      "200000 read\n"
     ]
    }
   ],
   "source": [
    "fname = f'{MIMIC_4_SAVE_DIR}/notes_labeled_icd9_filtered.csv'\n",
    "base_name = \"%s/disch\" % MIMIC_4_SAVE_DIR #for output\n",
    "tr, dv, te = split_data(fname, base_name=base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('%s/disch_train_split.csv' % (MIMIC_4_SAVE_DIR), encoding='utf-8',engine='python',dtype={\"icd_code\": str})\n",
    "dev_df=pd.read_csv('%s/disch_dev_split.csv' % (MIMIC_4_SAVE_DIR), encoding='utf-8',engine='python',dtype={\"icd_code\": str})\n",
    "test_df=pd.read_csv('%s/disch_test_split.csv' % (MIMIC_4_SAVE_DIR), encoding='utf-8',engine='python',dtype={\"icd_code\": str})\n",
    "# train_df=pd.read_csv(tr, encoding='utf-8',engine='python')\n",
    "# dev_df=pd.read_csv(dv, encoding='utf-8',engine='python')\n",
    "# test_df=pd.read_csv(te, encoding='utf-8',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209330\n",
      "188508\n",
      "7110\n",
      "13705\n"
     ]
    }
   ],
   "source": [
    "print(len(dfnl['subject_id']))\n",
    "print(len(train_df['subject_id']))\n",
    "print(len(dev_df['subject_id']))\n",
    "print(len(test_df['subject_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97708\n",
      "87935\n",
      "3257\n",
      "6515\n"
     ]
    }
   ],
   "source": [
    "print(len(dfnl['subject_id'].unique()))\n",
    "print(len(train_df['subject_id'].unique()))\n",
    "print(len(dev_df['subject_id'].unique()))\n",
    "print(len(test_df['subject_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97708\n",
      "87935\n",
      "3257\n",
      "6515\n"
     ]
    }
   ],
   "source": [
    "print(len(dfnl['subject_id'].unique()))\n",
    "print(len(train_df['subject_id'].unique()))\n",
    "print(len(dev_df['subject_id'].unique()))\n",
    "print(len(test_df['subject_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def build_vocab(vocab_min, infile, vocab_filename):\n",
    "    \"\"\"\n",
    "        INPUTS:\n",
    "            vocab_min: how many documents a word must appear in to be kept\n",
    "            infile: (training) data file to build vocabulary from\n",
    "            vocab_filename: name for the file to output\n",
    "    \"\"\"\n",
    "    with open(infile, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        #header\n",
    "        next(reader)\n",
    "\n",
    "        #0. read in data\n",
    "        print(\"reading in data...\")\n",
    "        #holds number of terms in each document\n",
    "        note_numwords = []\n",
    "        #indices where notes start\n",
    "        note_inds = [0]\n",
    "        #indices of discovered words\n",
    "        indices = []\n",
    "        #holds a bunch of ones\n",
    "        data = []\n",
    "        #keep track of discovered words\n",
    "        vocab = {}\n",
    "        #build lookup table for terms\n",
    "        num2term = {}\n",
    "        #preallocate array to hold number of notes each term appears in\n",
    "        note_occur = np.zeros(400000, dtype=int)\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            text = row[2]\n",
    "            numwords = 0\n",
    "            for term in text.split():\n",
    "                #put term in vocab if it's not there. else, get the index\n",
    "                index = vocab.setdefault(term, len(vocab))\n",
    "                indices.append(index)\n",
    "                num2term[index] = term\n",
    "                data.append(1)\n",
    "                numwords += 1\n",
    "            #record where the next note starts\n",
    "            note_inds.append(len(indices))\n",
    "            indset = set(indices[note_inds[-2]:note_inds[-1]])\n",
    "            #go thru all the word indices you just added, and add to the note occurrence count for each of them\n",
    "            for ind in indset:\n",
    "                note_occur[ind] += 1\n",
    "            note_numwords.append(numwords)\n",
    "            i += 1\n",
    "        #clip trailing zeros\n",
    "        note_occur = note_occur[note_occur>0]\n",
    "\n",
    "        #turn vocab into a list so indexing doesn't get fd up when we drop rows\n",
    "        vocab_list = np.array([word for word,ind in sorted(vocab.items(), key=operator.itemgetter(1))])\n",
    "\n",
    "        #1. create sparse document matrix\n",
    "        C = csr_matrix((data, indices, note_inds), dtype=int).transpose()\n",
    "        #also need the numwords array to be a sparse matrix\n",
    "        note_numwords = csr_matrix(1. / np.array(note_numwords))\n",
    "        \n",
    "        #2. remove rows with less than 3 total occurrences\n",
    "        print(\"removing rare terms\")\n",
    "        #inds holds indices of rows corresponding to terms that occur in < 3 documents\n",
    "        inds = np.nonzero(note_occur >= vocab_min)[0]\n",
    "        print(str(len(inds)) + \" terms qualify out of \" + str(C.shape[0]) + \" total\")\n",
    "        #drop those rows\n",
    "        C = C[inds,:]\n",
    "        note_occur = note_occur[inds]\n",
    "        vocab_list = vocab_list[inds]\n",
    "\n",
    "        print(\"writing output\")\n",
    "        with open(vocab_filename, 'w', encoding='utf-8') as vocab_file:\n",
    "            for word in vocab_list:\n",
    "                vocab_file.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in data...\n",
      "removing rare terms\n",
      "102923 terms qualify out of 282160 total\n",
      "writing output\n"
     ]
    }
   ],
   "source": [
    "vocab_min = 3\n",
    "vname = '%s/vocab.csv' % MIMIC_4_SAVE_DIR\n",
    "build_vocab(vocab_min, '%s/disch_train_split.csv' % (MIMIC_4_SAVE_DIR), vname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sort each data split by length for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    filename = '%s/disch_%s_split.csv' % (MIMIC_4_SAVE_DIR, splt)\n",
    "    df = pd.read_csv(filename, encoding='utf-8', engine='python',dtype={\"icd_code\": str})\n",
    "    df['length'] = df.apply(lambda row: len(str(row['text']).split()), axis=1)\n",
    "    df = df.sort_values(['length'])\n",
    "    df.to_csv('%s/%s_full.csv' % (MIMIC_4_SAVE_DIR, splt), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter each split to the top 50 diagnosis/procedure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #first calculate the top k\n",
    "# counts = Counter()\n",
    "# dfnl = pd.read_csv('%s/notes_labeled.csv' % MIMIC_3_DIR)\n",
    "# for row in dfnl.itertuples():\n",
    "#     for label in str(row[4]).split(';'):\n",
    "#         counts[label] += 1\n",
    "# codes_50 = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# codes_50 = [code[0] for code in codes_50[:Y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['274.9', 'V49.86', 'V58.67', '327.23', '428.32', '428.0', '585.6', '300.00', '584.9', 'V45.82', '401.9', '403.90', '427.31', '285.1', '412', '96.6', '38.97', '530.81', '427.89', '585.9', '272.0', '338.29', 'V15.82', '285.9', 'V58.61', 'V45.81', 'V12.54', '599.0', '278.00', '414.00', '486', '244.9', '305.1', 'V12.51', '564.00', '272.4', '250.00', '287.5', '493.90', '311', '276.51', '357.2', '414.01', 'V58.66', '38.93', '276.1', '276.2', '600.00', '496', '733.00']\n"
     ]
    }
   ],
   "source": [
    "MIMIC_4_DIR_ICD9 = '../mimicdata/mimic4_icd9'\n",
    "with open(f\"{MIMIC_4_DIR_ICD9}/top50_icd9_code_list.txt\", \"r\") as fd:\n",
    "    codes_50=[x.strip() for x in fd.readlines()]\n",
    "print(codes_50)\n",
    "\n",
    "with open('%s/TOP_%s_CODES.csv' % (MIMIC_4_DIR_ICD9, str(Y)), 'w') as of:\n",
    "    w = csv.writer(of)\n",
    "    for code in codes_50:\n",
    "        w.writerow([code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    print(splt)\n",
    "    hadm_ids = set()\n",
    "    with open('%s/%s_50_hadm_ids.csv' % (MIMIC_4_DIR_ICD9, splt), 'r') as f:\n",
    "        for line in f:\n",
    "            hadm_ids.add(line.rstrip())\n",
    "    with open('%s/notes_labeled_icd9_filtered.csv' % MIMIC_4_DIR_ICD9, 'r', encoding='utf-8') as f:\n",
    "        with open('%s/%s_%s.csv' % (MIMIC_4_DIR_ICD9, splt, str(Y)), 'w', encoding='utf-8') as of:\n",
    "            r = csv.reader(f)\n",
    "            w = csv.writer(of)\n",
    "            #header\n",
    "            w.writerow(next(r))\n",
    "            i = 0\n",
    "            for row in r:\n",
    "                hadm_id = row[1]\n",
    "                if hadm_id not in hadm_ids:\n",
    "                    continue\n",
    "                codes = set(str(row[3]).split(';'))\n",
    "                filtered_codes = codes.intersection(set(codes_50))\n",
    "                if len(filtered_codes) > 0:\n",
    "                    w.writerow(row[:3] + [';'.join(filtered_codes)])\n",
    "                    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    filename = '%s/%s_%s.csv' % (MIMIC_4_DIR_ICD9, splt, str(Y))\n",
    "    df = pd.read_csv(filename, encoding='utf-8', engine='python')\n",
    "    df['length'] = df.apply(lambda row: len(str(row['text']).split()), axis=1)\n",
    "    df = df.sort_values(['length'])\n",
    "    df.to_csv('%s/%s_%s.csv' % (MIMIC_4_DIR_ICD9, splt, str(Y)), index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icdproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
